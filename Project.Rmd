---
title: 'Statistical Learning Project'
author: 'Ammar Hasan'
date: '11 November 2018'
toc: true
fig_caption: yes

header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}

output: bookdown::pdf_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, results = 'markup', message = F)

# Load packages
library(nclSLR)
library(knitr)

# Load the data
data(Boston, package='nclSLR')

# Table function with rounding (uses kable)
table = function(dataset, cap, dp = 3){
  kable(format(round(dataset, dp), nsmall = dp), caption = cap)
}

```


\newpage

# Introduction 

This report summaries the steps undertaken to produce and evaluate linear regression models of the value of housing in Boston Standard Metropolitan to predict the value of logarithmic crime rate (lcrim) using other variables. The model would be built after exploratory and unsupervised statistical analysis of the data which is carried first to gain an understanding on the data characteristics and structure before hand. The models would be build using both sub-setting (best fit and step wise) and regularisation methods (LASSO and Ridge Fit) methods, these methods will be compared using k fold cross validation.

Any output (tables and plots) is placed in the Appendix at the end of the report with the R code that generated it, the description and analysis of the methods and their output is found in the document body which cross references the appendix content. Values in tables and other numerical results are corrected to 3 decimal places unless stated otherwise.

# Exploratory Data Analysis

Before building a linear model, it is wise to first understand the overall structure of the data itself to get a feeling for the data characteristics and how the variables relate to one another - especially how they relate to the response variable (lcrime).

## Data Spread and Location 

To analyse the distribution of the data, the quantiles and means will be examined. In particular, this part of the report will examine outliers, scale, consistency and certainty. 

### Mean Vector

Using the col means functions a vector of mean averages can be produced for all the predictors and the response variables in the Boston data-set. 

The returned table (transposed) is in table \@ref(tab:mean-vector) in Appendix A.2, and shows that the means are well spread out from one another, which suggests a difference in the nature of the measurements.

Examining the structure of the variables in the Boston data set using the ?Boston confirms that the nature of the measurements vary from Full-value property-tax rate per $10,000 for tax to Nitrogen oxides parts per 10 million for nox for instance, which obviously suggests that the measurements cannot be directly compared scale to scale (standarisation might be required).

### Box Plot and Quantiles

As previously stated in the previous section, the variables are of different natures and scales, hence any scale to scale comparsion needs standarisation. To standardise the data a scale transform was applied using the base R scale() function, and using the boxplot base function the plot in figure \@ref(fig:box-plot) is generated. 

The following stands out of the plot:

* black, rm, zn and medv predictor variables have significantly more outliers than the other variables.And hence more uncertain and also their averages can get skewed.

* chas predictor variable semms to have a very tight ranges that are practicaly identical. This is because this is a binary variable.

* zn, rad and tax predictor variables have a short Q1 to Q2 range compared to the Q2 to Q3 range, suggesting that the lower values of the data are very tightly clustered. black has the opposite problem.

* rm, lstat, mdev and ptratio have long minimum and maximum ranges in comparision to their IQR ranges, and hence more exterme values. This means that rheir averages can get skewed.

## Data Relationships 

### Pairs Plot and Correlation Matricies

\newpage

# Unsupervised Learning

## Principle Component Analysis

## Cluster Analysis

\newpage

# Supervised Learning (Linear Model)

\newpage

# Appendix 

This section contains all supplementary material and is divided into three sections (Tables, Plots and Abbreviations). The code required to generate the supplementary material is also included

## A.1 Abbrevations

\newpage

## A.2 Tables 

### Code to Generate Table \@ref(tab:mean-vector) (Transposed and Correct to 3DP)
```{r mean-vector}
table(colMeans(Boston), '')
```

\blandscape

### Code to Generate Table \@ref(tab:cor-matrix) (Correct to 3DP)
```{r cor-matrix}
table(var(Boston), 'Correlation Matrix (3DP)')
```

\newpage

### Code to Generate Table \@ref(tab:pca-summary) (Correct to 3DP)
```{r pca-summary}
# Perform PCA based on the standardised data (means and data nature vary)
pca = prcomp(Boston, scale=TRUE)
table(summary(pca)$importance, 'PCA Summary (Contribution to Variation)')
```

### Code to Generate Table \@ref(tab:pca-comps) (Correct to 3DP)
```{r pca-comps}
# List PC 1, 2 and 3 
table(pca$rotation[,1:3], 'PCA Components')
```

\elandscape

\newpage

## A.3 Plots

### Code to Generate Figure \@ref(fig:box-plot)
```{r box-plot, fig.cap='Box Plot'}
# scale transforms to deal with the variation in the nature of the measurements
boxplot(scale(Boston), cex.axis=0.6)
```

\blandscape

\newpage

### Code to Generate Figure \@ref(fig:pairs-plot)
```{r pairs-plot, fig.cap='Pairs Plot'}
pairs(Boston, cex=0.0005)
```

\elandscape

\newpage

### Code to Generate Figure \@ref(fig:scree-plot)
```{r scree-plot, fig.cap='Scree Plot'}
plot(pca, type='l', main='Scree Plot for Boston Housing Values')
title(xlab='Principle Component number')
```

### Code to Generate Figure \@ref(fig:pca-plot)
```{r pca-plot, fig.cap='PCA Plot'}
# Plot PCA 1 against PCA 2
plot(pca$x[,1], pca$x[,2], main ="Principle Component 1 vs 2 for Boston Housing Values",
     xlab="Component 1", ylab="Component 2")
```