---
title: 'Statistical Learning Project'
author: 'Ammar Hasan'
date: '11 November 2018'
toc: true
fig_caption: yes

header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}

output: bookdown::pdf_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, results = 'markup', message = F)

# Load packages
library(nclSLR)
library(knitr)
library(leaps)
library(glmnet)

# Load the data
data(Boston, package='nclSLR')
```

\newpage

# Introduction 

This report summaries the steps undertaken to produce and evaluate linear regression models of the value of housing in Boston Standard Metropolitan to predict the value of logarithmic crime rate (lcrim) using other variables. The model would be built after exploratory and unsupervised statistical analysis of the data which is carried first to gain an understanding on the data characteristics and structure before hand. The models would be build using both sub-setting (best fit and step wise) and regularisation methods (LASSO and Ridge Fit) methods, these methods will be compared using k fold cross validation.

Any output (tables and plots) is placed in the Appendix at the end of the report with the R code that generated it, the description and analysis of the methods and their output is found in the document body which cross references the appendix content. Values in tables and other numerical results are corrected to 3 decimal places unless stated otherwise.

# Exploratory Data Analysis

Before building a linear model, it is wise to first understand the overall structure of the data itself to get a feeling for the data characteristics and how the variables relate to one another - especially how they relate to the response variable (lcrime).

## Data Spread and Location 

To analyse the distribution of the data, the quantiles and means will be examined. In particular, this part of the report will examine outliers, scale, consistency and certainty. 

### Mean Vector

Using the col means functions a vector of mean averages can be produced for all the predictors and the response variables in the Boston data-set. 

The returned table (transposed) is in table \@ref(tab:mean-vector) in Appendix A.2, and shows that the means are well spread out from one another, which suggests a difference in the nature of the measurements.

Examining the structure of the variables in the Boston data set using the ?Boston confirms that the nature of the measurements vary from Full-value property-tax rate per $10,000 for tax to Nitrogen oxides parts per 10 million for nox for instance, which obviously suggests that the measurements cannot be directly compared scale to scale (standarisation might be required).

### Box Plot and Quantiles

As previously stated in the previous section, the variables are of different natures and scales, hence any scale to scale comparison needs standarisation. To standardise the data a scale transform was applied using the base R scale() function, and using the boxplot base function the plot in figure \@ref(fig:box-plot) is generated. 

The following stands out of the plot:

* black, rm, zn and medv predictor variables have significantly more outliers than the other variables.And hence more uncertain and also their averages can get skewed.

* chas predictor variable seems to have a very tight ranges that are practically identical. This is because this is a binary variable.

* zn, rad and tax predictor variables have a short Q1 to Q2 range compared to the Q2 to Q3 range, suggesting that the lower values of the data are very tightly clustered. black has the opposite problem.

* rm, lstat, mdev and ptratio have long minimum and maximum ranges in comparison to their IQR ranges, and hence more extreme values. This means that their averages can get skewed.

## Data Relationships 

This section of the report will look into how the variables (predictors and response) in bivariate data relate and interact using numerical correlation matrices and graphic pairs plot

### Pairs Plot 

The following relationships stick out when observing the pairs plot for the response against other variables in figure \@ref(fig:pairs-plot):

* Relationships/correlation with lcrime:
    + age and medv has a moderate negative relationship with lcrime 
    + nox and lstat has a strong/moderate positive relationship with lcrim
    + rm and zn both have weak/moderate negative relationships with lcrime
    + tax, rad, pratio, indus and black appear to have unclear correlation
    
* Predictor variables relationships: 
    - Some predictors have strong relations with one another: rm has a strong negative relationship with lstat but a strong positive one with medv. medv and lstat also have a strong negative relationship

* Chas (river dummy variable) and disf (distance to Boston employment centered) appear to have values in levels and are also difficult to analyse in a pairs plot


### Correlation Matricies

The correlation matrix in table \@ref(tab:cor-matrix) confirms the findings of the previous section but also helps clarify some of relationships that were unclear before: 

* Chas has a very weak relationship with lcrime, and a weak or very weak relationship with most other variables.
* disf has a moderate negative relationship with lcrime, a strong/moderate negative relationship with indus and a positive moderate relation with zn
* Tax and rad have strong relationships with lcrime that were difficult to spot before due to irregularities in their plots. Moreover, indus has a moderate positive relationship with lcrime and ptartio a weak positive one.
* Tax and rad have a very strong positive relationship

### Data Relationships Summary

To summarise, it seems that the relationships suggest that there are a couple of variables that might have a strong impact to model (e.g. rad or tax). Moreover, the relationships also suggest that many will be subsetted due to relationships that can be represented with other variables(e.g. rad or tax), or very poor relationships with all variables (e.g. chas).

\newpage

# Unsupervised Learning

This section looks into apply unsupervised learning techniques to help understanding patterns and structures in the data to help understand their effects on the model. In this report, Principle Component Analysis will be used to help find which set of predictors cause the most variation on the data to help with model coefficient interpretation and gaining an understanding of which predictors contribute to the model. 

## Principle Component Analysis

### Variation Proportions

Table \@ref(tab:pca-summary) shows the summary of PCA run on the data, showing the variance each PC to and the accumulation of it. The summary shows that the first component contributed to 50% of the variance, and the first 4 contribute to 70%. Since the first 3 contribute to 70% and also where the variation curve in the scree plot in \@ref(fig:scree-plot) diminishes for a second time. 


### Component Interpretation (According to Table \@ref(tab:pca-comps))

#### Component 1

Dominated by positive lcrime, tax, indus and nox. This means that it represents areas with large non-retail business but high crime and nitrogen oxide pollution.

#### Component 2

Dominated by negative rm and medv, meaning that it represents less median house values and number of rooms.

#### Component 3

Dominated high accessibility highways, tax rate and residual areas.

#### Plot

A plot of the observations scores for component 1 vs component2 is shown in figure \@ref(fig:pca-plot) shows most observations score high for component 2 but are more varied for component 1. Meaning that most observations have relative low median house value and number of rooms, but a varied crime, pollution and non-retail business.

\newpage

# Supervised Learning (Linear Modelling)

In this section of the report linear models are fitting and tested against each other using K Fold Cross Validation. By the end of this section a summary will conclude which models are best and why.

## Model Fitting 

### Subset Selection using Best Fit

Best Fit Subset Selection Tries all possible predictors p combinations to find the "best" model using $SS_E$ (optimisation problem). The method's results are shown in table \@ref(tab:best-sub-select) as the selected best predictors from 13 variables (everything except lcrime) to 1 variable.

#### Subsetting Results analysis

When we look at the results we can notice that the first variable to be dropped is tax. tax being the first dropped predictor seems to lines up with the discussion in the Data Relationships Summary, as it was stated that either tax/rad can be represented by the other (and hence can be dropped). 

Moreover it was also stated in the Relationships summary that chas correlated little to lcrime and other variables (little to no prediction can be made with it), so it's no surprise that it was dropped second. 

Also, it can be noticed that usually the highest impacting predictors in the PCs stick for longer before dropping with a few exceptions. This particularly true for PC1, as with the exception of tax (which was subsetted for rad) some of the high scoring variables stuck around for long (e.g. nox), which is not surprising since it would be sensible for the most variation causing variables to cause variation to lcrim (and hence become important for prediction).

#### Which Subset to Select

Nonetheless, to decide which number of predictors would be the best choice, there are various techniques that can be followed to evaluate whether removing variables is worthwhile ($SS_E$ based or MSE based). 

The results using based $SS_E$ measurements (Adjusted $R^2$, BIC, $Cp$) are shown in figure \@ref(fig:best-sub-cv), and they show that generally the  gain from dropping out predictors is optimal somewhere around 5-10 before becoming worse. 
 
For the K Fold Cross Validation (10 fold picked here) also shown in figure \@ref(fig:best-sub-cv), the best result occurs with 9 predictors which is similar with other results (and is identical to the adjusted Cp choice), and since this measurement is based on experimentation with tests errors it is preferred. The 10 Fold Cross Validation choice of 9 predictors would result in chas, rm, mdev and tax being removed from the model.   

#### Selected Subset Coefficient Discussion

The resulting coefficients for the selected predictors is shown in table \@ref(tab:best-sub-coef), and seems to show nox and rad as the strongest positively influencing predictors. This lines up with nox and rad positive strength in the first PC in the PCA analysis and their strong positive correlation. The same can be observed with the strongest negative component (disf anad age), which also were strong in PC1 and had strong/moderate negative correlation with lcrim . 

### Ridge Regression 

Ridge Regression uses a modified loss function to add a penalty to large coefficients to improve predictive solution (constraints variance).

#### Lambda Choice 

Lambda decides how much the algorithm penalties large coefficient, the more it does so the more the values slope down as seen in figure \@ref(fig:ridge-fit-lambdas). Most of the values seem to start low and slope slowly, except nox(7), disf(7) and rad(8), with nox especially dominating the coefficient sizes before dropping next to lambda 0. Nonetheless, to know which lambda choice would make the most sense, a 10 fold cross validation is carried in figure \@ref(fig:ridge-fit-cv) and shows that the MSE start low and only starts to pick pace and go up once it crosses midway between $log(lambda) = 0$ and $log(lambda) = 5$. The exact minimum MSD is not clear from the graph, but using the "lambda.min" field returns a 0.001 for the lambda also as seen in figure's \@ref(fig:ridge-fit-cv) code.

#### Selected Lambda Coefficent Discussion 

As seen in figure \@ref(fig:ridge-fit-lambdas), nox(7), disf(7) and rad(8) seemed to be the most dominant coefficient and this can also be observed in the exact values with ideal lambda (0.001) seen in table \@ref(tab:ridge-fit-coef). The coefficients selected seem similar to the coefficients seen with best subset selection, but lower due to the size penalty added by Ridge Regression. Nonetheless, just like the Best Subset coefficient, the values most correlated to lcrime and the strongest in PC1 generally being the most dominant as discussed with the Best Subset coefficients. 

### LASSO

LASSO is quite similar to Ridge Regression, however unlike ridge regression which always gets all p variables LASSO can subset (coefficients can become zero). This is because of the modified $SS_E$ which takes the absolute value instead of the square of each coefficient. 

#### Lambda Choice

Similarly to Ridge Regression, lambda decides how much the algorithm penalises large coefficients. The values of coefficients against lambda can be seen in \@ref(fig:lasso-lambdas), which is quite similar to the results with Ridge Regression but the coefficent seem closer to zero (as some of them would actual equal it!). Nonetheless, as with Ridge Regression, to find the ideal lambda value MSE in a 10 fold cross validation is used, and as seen in \@ref(fig:ridge-fit-cv) the results are quite similar to Ridge Regression and in fact they both have the same lambda for the minimum MSE (0.001).


#### Selected Lambda Coefficent Discussion

The values for the coefficients are quite similar to Ridge Regression coeficients with minor differences, but since LASSO's main difference with Ridge Regression is its ability to subset the predictors they will be the main concern of this discussion. It seems LASSO decided to only subset tax out (at least correct to 3 DP), which is probably because it can be easily represnted with rad due to their strong correlation as seen in the Data Relationships section 

## Model Evaluation Using k-fold Cross Validation 

## Best Model Discussion and Conclusions

\newpage

# Appendix 

This section contains all supplementary material and is divided into three sections ("Abbreviations and Short hands", "Functions", "Tables" and "Plots"). The code required to generate the supplementary material is also included

## A.1 Abbrevations and Shorthands

### Abbrevations

(X)DP: X Decimal Points

PCA: Principle Component Analysis

PC: Principle Component

$SS_E$: Residual Sum of Squares 

MSE: Mean Square Error

$R^2$ or Rsq: Coefficient of Determination

$C_p$: Mallow's $C_p$

BIC: Bayesian Information Criterion

LASSO: Least Absolute Shrinkage and Selection Operator

### Variable Shorthands

lcrim: Natural logarithm of the per capita crime rate by town.

zn: Proportion of residential land zoned for lots over 25,000 sq.ft.

indus: Proportion of non-retail business acres per town.

chas: Charles River dummy variable (=1 if tract bounds river; =0 otherwise).

nox: Nitrogen oxides concentration (parts per 10 million).

rm: Average number of rooms per dwelling.

age: Proportion of owner-occupied units built prior to 1940.

disf: A numerical vector representing an ordered categorical variable with four levels depending on the weighted mean of the distances to five Boston employment centres (=1 if distance < 2.5, =2 if 2.5 <= distance < 5, =3 if 5 <= distance < 7.5, =4 if distance >= 7.5).

rad: Index of accessibility to radial highways.

tax: Full-value property-tax rate per $10,000.

pratio: Pupil-teacher ratio by town.

black: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.

lstat: Lower status of the population (percent).

medv: Median value of owner-occupied homes in $1000s.

\newpage

## A.2 Functions

```{r functions}
# Table function with rounding (uses kable)
table = function(dataset, cap, dp = 3){
   kable(format(round(dataset, dp), nsmall = dp), caption = cap)
}

# Table function (non num)
tableTxt = function(dataset, cap){
  kable(dataset, caption = cap)
}

# Predict for reg subsets (no predict function)
predict.regsubsets = function(object, newdata, id, ...) {
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  coefi = coef(object, id=id)
  xvars = names(coefi)
  return(mat[,xvars] %*% coefi)
}
```

\newpage

## A.3 Tables 

### Code to Generate Table \@ref(tab:mean-vector) (Transposed and Correct to 3DP)
```{r mean-vector}
table(colMeans(Boston), '')
```

\blandscape

### Code to Generate Table \@ref(tab:cor-matrix) (Correct to 3DP)
```{r cor-matrix}
table(cor(Boston), 'Correlation Matrix (3DP)')
```

\newpage

### Code to Generate Table \@ref(tab:pca-summary) (Correct to 3DP)
```{r pca-summary}
# Perform PCA based on the standardised data (means and data nature vary)
pca = prcomp(Boston, scale=TRUE)
table(summary(pca)$importance, 'PCA Summary (Contribution to Variation)')
```

### Code to Generate Table \@ref(tab:pca-comps) (Correct to 3DP)
```{r pca-comps}
# List PC 1, 2 and 3 
table(pca$rotation[,1:3], 'PCA Components')
```

\newpage

### Code to Generate Table \@ref(tab:best-sub-select)
```{r best-sub-select}
# Get scaled results and response
X_raw = as.matrix(Boston[-1])
X = scale(X_raw)
y = Boston[,1]

# fit model
bss = regsubsets(y ~ ., data=data.frame(y,X), method="exhaustive", nvmax= 13)

# Summarise
bssSummary = summary(bss)

tableTxt(bssSummary$outmat, "Best Subset Selection")
```

\elandscape

```{r best-sub-coef}
# use coef function to find the coefficient 
# id represents the choice for predictor number
table(coef(bss, id = 9), "Best Subset Coefficient Selection (9 Predictors)")
```


```{r ridge-fit-coef}
## Fit a ridge regression model with idea lambda (~0.006)
ridgeFit = glmnet(X, y, alpha=0, standardize=FALSE, lambda= 0.006428073)
table(as.data.frame(as.matrix(coef(ridgeFit, s = 0.006428073))),
      "Ridge Regression Coefficients with Lambda = ~0.006")
```


```{r lasso-coef}
## Fit a LASSO regression model with idea lambda (~0.016)
lassoFit = glmnet(as.matrix(Boston[-1]), 
                  as.vector(Boston$lcrim), alpha=1, standardize=FALSE, lambda= 0.01629751)
table(as.data.frame(as.matrix(coef(lassoFit, s = 0.01629751))),
      "LASSO Coefficients with Lambda = ~0.016")
```

\newpage

## A.4 Plots

### Code to Generate Figure \@ref(fig:box-plot)
```{r box-plot, fig.cap='Box Plot'}
# scale transforms to deal with the variation in the nature of the measurements
boxplot(scale(Boston), cex.axis=0.6)
```

\blandscape

\newpage

### Code to Generate Figure \@ref(fig:pairs-plot)
```{r pairs-plot, fig.cap='Pairs Plot'}
pairs(Boston, cex=0.0005)
```

\elandscape

\newpage

### Code to Generate Figure \@ref(fig:scree-plot)
```{r scree-plot, fig.cap='Scree Plot'}
plot(pca, type='l', main='Scree Plot for Boston Housing Values')
title(xlab='Principle Component number')
```

### Code to Generate Figure \@ref(fig:pca-plot)
```{r pca-plot, fig.cap='PCA Plot'}
# Plot PCA 1 against PCA 2
plot(pca$x[,1], pca$x[,2], main ="Principle Component 1 vs 2 for Boston Housing Values",
     xlab="Component 1", ylab="Component 2")
```

\newpage

### Code to Generate Figure \@ref(fig:best-sub-cv)
```{r best-sub-cv, fig.cap='Best Subset Predictor Selection'}
# *** SSE Based Measurements ***

# Find best score for SSE based measurements (already done by bss summary)
bestAdjr2 = which.max(bssSummary$adjr2)
bestCp = which.min(bssSummary$cp)
bestBic = which.min(bssSummary$bic)

# *** 10 fold cross validation ***

# 10 fold cv

# Set the seed to make the analysis reproducible
set.seed(1)

# 10-fold cross validation
nFolds = 10

# Find n and p
p = ncol(Boston) - 1 # number of predictors (no lcrim)
n = nrow(Boston)

# Sample fold-assignment index
foldIndex = sample(nFolds, n, replace=TRUE)

# Hold fold sizes 
foldSizes = numeric(nFolds)

# Compute fold sizes
for(k in 1:nFolds) foldSizes[k] = length(which(foldIndex==k))

# create the matrix to store the folds
cvBssErrors = matrix(NA, p, nFolds)

# Find MSEs for all fold combination
for(k in 1:nFolds) {
  # Fit models by best-subset selection (no k-th fold)
  bssTmpFit = 
    regsubsets(lcrim ~ ., data=Boston[foldIndex!=k,], method="exhaustive", nvmax=p)
  
  # For each model M_m where m=1,...,p:
  for(m in 1:p) {
    # Compute fitted values for the k-th fold 
    bssTmpPredict = predict(bssTmpFit, Boston[foldIndex==k,], m)
    # Work out MSE for the k-th fold
    cvBssErrors[m, k] = mean((Boston[foldIndex==k,]$lcrim - bssTmpPredict)^2)
  }
}

# Compute a weighted average MSE
bssMse = numeric(p)
# For models M_1,...,M_p:
for(m in 1:p) {
  bssMse[m] = weighted.mean(cvBssErrors[m,], w=foldSizes)
}

# Identify model with the lowest MSE
bestCv = which.min(bssMse)

# *** Plotting ***

# Create multi-panel plotting device:
par(mfrow=c(2,2))

# Produce plots, highlighting optimal value of preductors:
plot(1:13, bssSummary$adjr2, xlab="Number of predictors", ylab="Adjusted Rsq",
type="b")
points(bestAdjr2, bssSummary$adjr2[bestAdjr2], col="red", pch=16)

plot(1:13, bssSummary$cp, xlab="Number of predictors", ylab="Cp", type="b")
points(bestCp, bssSummary$cp[bestCp], col="red", pch=16)

plot(1:13, bssSummary$bic, xlab="Number of predictors", ylab="BIC", type="b")
points(bestBic, bssSummary$bic[bestBic], col="red", pch=16)

plot(1:p, bssMse, xlab="Number of predictors", ylab="10-fold CV Error", type="b")
points(bestCv, bssMse[bestCv], col="red", pch=16)
```

\newpage

### Code to Generate Figure \@ref(fig:ridge-fit-lambdas) 
```{r ridge-fit-lambdas, fig.cap="Ridge Fit Coefficents versus Lambdas"}
# grid of values for lambda (10^5 to 10^-3)
grid = 10^seq(5, -3, length=100)

## Fit a ridge regression model for each value of the tuning parameter
# alpha 0 -> Ridge regression not LASSO
ridgeFit = glmnet(X, y, alpha=0, standardize=FALSE, lambda=grid)

plot(ridgeFit, xvar="lambda", col=1:13, label=TRUE)
```

\newpage

### Code to Generate Figure \@ref(fig:ridge-fit-cv) with Minimum Result
```{r ridge-fit-cv, fig.cap="Ridge Fit 10 Fold Cross Validation"}
# Fit a ridge regression model using all lambdas with cv validation
# alpha 0 -> Ridge regression not LASSO
ridgeFitCv = cv.glmnet(X, y, alpha=0, standardize=FALSE, lambda=grid)

plot(ridgeFitCv) # plot cross validated error

# Find exact minimum
(lambdaMin = ridgeFitCv$lambda.min)
```

\newpage

### Code to Generate Figure \@ref(fig:lasso-lambdas) 
```{r lasso-lambdas, fig.cap="LASSO Coefficents versus Lambdas"}
# Fit a ridge regression model for each value of the tuning parameter
# alpha 1 -> LASSO
lasso = glmnet(X, y, alpha=1, standardize=FALSE, lambda=grid)

plot(lasso, xvar="lambda", col=1:13, label=TRUE)
```

\newpage

### Code to Generate Figure \@ref(fig:lasso-cv) with Minimum Result
```{r lasso-cv, fig.cap="LASSO 10 Fold Cross Validation"}
# Fit a ridge regression model using all lambdas with cv validation
# aplha 1 -> LASSO
lassoCv = cv.glmnet(X, y, alpha=1, standardize=FALSE, lambda=grid)

plot(ridgeFitCv) # plot cross validated error

# Find exact minimum
(lambdaMin = lassoCv$lambda.min)
```

